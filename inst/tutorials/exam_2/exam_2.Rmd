---
title: "Forests of the Future: Practice Exam 2"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    language:
      en:
        button:
          runcode: Test Code
          submitanswer: Run Code
          questionsubmit: Submit Answer
          questiontryagain: Change my answer
runtime: shiny_prerendered
description: Forests of the Future Exam 2
---

```{css echo=FALSE}
@media print {
  .topicsContainer,
  .topicActions,
  .exerciseActions .skip {
    display: none;
  }
  .topics .tutorialTitle,
  .topics .section.level2,
  .topics .section.level3:not(.hide) {
    display: block;
  }
  .topics {
    width: 100%;
  }
  .tutorial-exercise, .tutorial-question {
    page-break-inside: avoid;
  }
  .section.level3.done h3 {
    padding-left: 0;
    background-image: none;
  }
  .topics .showSkip .exerciseActions::before {
    content: "Topic not yet completed...";
    font-style: italic;
  }
}
```

```{r setup_hide, include=FALSE}
library(learnr)
library(fofpack)

custom_checker <- function(label, user_code, check_code, envir_result, evaluate_result, envir_prep, last_value, stage, ...) {
  # this is a code check
  if(stage == "check") {
    
    #fofpack::send_env_to_RStudio(envir_prep)
    
    if(label != "PR_model_tune") {
      rstudioapi::sendToConsole(user_code, focus = TRUE)
    }
    
    fofpack::set_env(envir_result)
    
    # try(save.image(file.path(system.file(package = "fofpack"), "week_5_progress.Rdata"),
    #            safe = FALSE),
    #     silent = TRUE)

    list(message = "Code Run; Results Now Available in RStudio.", correct = TRUE, type = "success", location = "append")
    
  }

}

tutorial_options(exercise.checker = custom_checker,
                 exercise.timelimit = 300)

knitr::opts_chunk$set(echo = FALSE)
```

## Florida Pine Rocklands

In this assignment we will be working with Pine Rockland data for South Florida parks. You will be constructing a model to predict the occurrence of a plant species using proportional land cover as predictors. You will be assigned a species randomly. Fill in the blank below with your name and click 'Run Code' and your assignment will be generated. Please read the results to see which speciesyou are working on. Otherwise, everyone's exam is the same.

### Setup

```{r setup, include=FALSE}
library(fofpack)
library(tidyverse)
library(tidymodels)

```

The following code loads the packages you will need for this assignment, and the dataset you will be using (and clears the workspace). Don't forget to always click 'Run Code' for each code box, which runs your code in RStudio, and allows you to access the results in later code boxes.

```{r do_setup, exercise=TRUE}
rm(list = ls())
library(fofpack)
library(tidyverse)
library(tidymodels)

data("IRC")
my_name <- "___"

set.seed(digest::digest2int(my_name) + 12345)
species <- IRC %>%
  filter(Introduced == "Not introduced") %>%
  filter(Occurrence %in% c("Present", "Absent")) %>%
  group_by(ScientificName) %>%
  summarise(num_pres = sum(Occurrence == "Present")) %>%
  filter(num_pres > 60, num_pres < 145) %>%
  slice_sample(n = 1) %>%
  pull(ScientificName)
cat("The species you will be working with is:",
    species, sep = "\n")
```

```{r do_setup-check}
ls()
```

### Exercise 1: Filter your data

Filter your the `IRC` dataset so that it only contains your species. Replace the blank with the correct code for the task. Note that the previous code block stored your species name in the R object `species`. You can choose to use this, or not!

```{r filter, exercise=TRUE}

mysp_dat <- IRC %>%
  ___

mysp_dat

```

```{r filter-check}
ls()
```

### Exercise 2: Merge parks data

The `parks_LC_wide` dataset has data on the land cover categories for each of our parks. Merge this data with your species dataset using `left_join()`

```{r merge, exercise=TRUE}
data("parks_LC_wide")
mysp_dat <- mysp_dat %>%
  ___

mysp_dat

```

```{r merge-check}
ls()
```

The above may have led to some missing data for some parks (not all parks have land cover data). The Random Forest model cannot deal with missing data so we need to remove it. Run the next code box which uses the handy `drop_na()` function automatically remove any row that have any missing data.

```{r drop_na, exercise=TRUE}

mysp_dat <- mysp_dat %>%
  drop_na()

mysp_dat

```

```{r drop_na-check}
ls()
```

### Exercise 3: Add area

We are also going to use the area of a park in our model this time. Currently the variable `size`, which contains the park area, is a character vector (because it contains "acres" denoting the units). You can extract a number from a character vector `x` using the following code: `parse_number(x)`. Using this information, replace the `size` column in `mysp_dat` with a `numeric` variable containing the park's size. Don't forget to replace `x` with the object you want to convert.

```{r add_area, exercise=TRUE}


```

```{r add_area-check}
ls()
```

<div id="add_area-hint">
**Remember:** You can replace a column using `mutate()`. Or you can just directly replace an element using the `$` operator: e.g. `mysp_dat$column_name <- transformed_data`
</div>

### Exercise 4: Split your data

Split the data into a training and test dataset using `initial_split()`. Fill in the blanks below. Put 75% of the data in the training dataset. Use the `Occurrence` column as the `strata` argument. Thene extract the training data set.

```{r model_split, exercise=TRUE}

data_split <- initial_split(mysp_dat, prop = ___, strata = ___)

data_train <- ___

data_train
```

```{r model_split-check}
ls()
```

### Exercise 5a: Setup a recipe

A `recipe` let's us apply a set of transformation to our data that are easily repeatable. Here we will keep it simple. We have a bunch of extra variable we won't be using in the model. We can remove these in our recipe so that we only have our response and land cover predictors left. Land cover variable all have the same prefix so we can use the `starts_with()` function to select them. 

Fill in the blank in the formula to specify all variables as predictors.
Also, we want to add `size` to our model. Fill in the blank in `step_select()` to make sure `size` gets included.

```{r model_recipe, exercise=TRUE}
LC_recipe <- recipe(Occurrence ~ ___, 
                    data = data_train) %>%
  step_select(all_outcomes(), starts_with("LC: "), ___,
              skip = TRUE)

LC_recipe

```

```{r model_recipe-check}
ls()
```

<div id="model_recipe-hint">
**Remember:** Functions that select variables in `tidyverse` and `tidymodels` generally refer to variable names *without* double quoting them.
</div>

### Exercise 5b: Check recipe by prepping and baking

Check if you've done it right by prepping the recipe and then baking it with `new_data = NULL`. Print out the column names of `test` and check you only have the `Occurrence`, the `"LC: "` prefixed variables, and `size`.

```{r prep_recipe, exercise=TRUE}
test <- prep(LC_recipe) %>%
  bake(new_data = NULL)

___
```

```{r prep_recipe-check}
ls()
```

### Exercise 6: Setup a Model and Workflow

You are going to fit a Random Forest model. Fill in the first blank to create a Random Forest model object called `LC_mod` and set it's engine to `'ranger'`. We have also added an extra argument to the `set_engine()`. This tells the model fitting algorithm (`ranger`) to estimate a measure of "importance", which we can use later to look at what variables were most important in predicting our species' occurrence. Fill in the last line with code to set the mode to `'classification'`.

```{r model_mod, exercise=TRUE}
LC_mod <- ___() %>%
  set_engine('ranger', importance = "impurity") %>%
  ____

LC_mod
```

```{r model_mod-check}
ls()
```

### Exercise 7: Make Workflow

Create a `workflow` object and add your recipe and model by filling in the blanks.

```{r model_wf, exercise=TRUE}
LC_wf <- workflow() %>%
  ____ %>%
  ____ 

LC_wf
```

```{r model_wf-check}
ls()
```

### Exercise 8a: Fit the model

Now you can fit the model. Use `last_fit()` to automatically fit the model and test it on your `data_split`. Put the results in an object called `LC_fit`.

```{r model_fit, exercise=TRUE}
LC_fit <- LC_wf %>%
  last_fit(split = ____)

LC_fit
```

```{r model_fit-check}
ls()
```

### Exercise 8b: Fit the model

Print out the metrics (there are multiple ways to do this).

```{r model_print, exercise=TRUE}


```

```{r model_print-check}
ls()
```

### Look at variable importance

We can extract our model from the `last_fit` object and then visualize the importance values that were calculated using the `vip` package.

```{r model_vip, exercise=TRUE}
library(vip)

LC_wf_fit <- LC_fit$.workflow[[1]]

LC_fit_mod <- LC_wf_fit %>%
  extract_fit_engine()

vip_scores <- vi(LC_fit_mod)

vip(vip_scores, num_features = 15)

```

```{r model_vip-check}
ls()
```

### Bonus Exercise 1

Plot the ROC curve for your model for the test data.

```{r model_curve, exercise=TRUE}
LC_fit %>%
  collect_predictions() %>%
  roc_curve(___, truth = ___) %>%
  autoplot()
```

```{r model_curve-check}
ls()
```

### Bonus Exercise 2

Make predictions for your full dataset (`mysp_dat`) using the `augment()` function. Call the object `mysp_preds`

```{r model_predict, exercise=TRUE}
mysp_preds <- ___

```

```{r model_predict-check}
ls()
```

<div id="model_predict-hint">
**Hint:** A previous code block extracted the fitted workflow object and stored it in `LC_wf_fit`. You can use this object with `augment()` to make predictions on new data (see `?augment.workflow'.
</div>

### Bonus Exercise 3

Plot the predictions you just made against the parks' `size` using `geom_line()`.

```{r model_plot, exercise=TRUE}
ggplot(___, aes(___)) +
  geom_line(___)
```

```{r model_plot-check}
ls()
```

That is it, you are done! Please submit your hash code to Canvas.


## Submit

```{r context="server"}
learnrhash::encoder_logic()
```

Once you have completed the assignment to your satisfaction, please click the 'generate' button below. This will create a text code that you can copy and paste into the assignment text submission form on canvas, and which I can use to regenerate your answers. Please make sure you copy the entire code. The easiest way is to click the copy button in at the top right. This will copy the entire code to the clipboard.  


```{r encode, echo=FALSE}
learnrhash::encoder_ui(ui_before = NULL)
```

<!--
### Decode

```{r context="server"}
learnrhash::decoder_logic()
```

```{r decode, echo=FALSE}
learnrhash::decoder_ui()
```
-->


